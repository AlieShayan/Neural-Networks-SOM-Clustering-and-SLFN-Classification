{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15eb37eb",
   "metadata": {},
   "source": [
    "# Project 1: Clustering with SOM\n",
    "## Imports and Setup\n",
    "\n",
    "Basic imports, sklearn utilities, MiniSom, and matplotlib configuration. Includes robust MiniSom import/installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478f7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from minisom import MiniSom\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a91de",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "Load the digits dataset, scale the features, and split into training, validation, and test sets (60/20/20 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2f6aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits dataset loaded: 1797 samples, 64 features.\n",
      "Number of classes: 10\n",
      "Data scaled using MinMaxScaler.\n",
      "Initial data split: Initial Train (1437), Final Test (360)\n",
      "Train/Validation split: Final Train (1077), Validation (360)\n",
      "Digits data prepared and split into Train/Validation/Test sets.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data # Original data (8x8=64 features)\n",
    "y = digits.target # Labels (0-9)\n",
    "print(f\"Digits dataset loaded: {X.shape[0]} samples, {X.shape[1]} features.\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"Data scaled using {type(scaler).__name__}.\")\n",
    "\n",
    "# 1. Split into Initial Train and Final Test sets\n",
    "X_train_init, X_test, y_train_init, y_test, X_train_init_orig, X_test_orig = train_test_split(\n",
    "    X_scaled, y, X, # Split scaled X, y, AND original X\n",
    "    test_size=0.2,    # 80% initial train, 20% final test\n",
    "    random_state=42,\n",
    "    stratify=y )\n",
    "print(f\"Initial data split: Initial Train ({X_train_init.shape[0]}), Final Test ({X_test.shape[0]})\")\n",
    "\n",
    "# 2. Split Initial Train into Final Train and Validation sets\n",
    "X_train_final, X_val, y_train_final, y_val, X_train_final_orig, X_val_orig = train_test_split(\n",
    "    X_train_init, y_train_init, X_train_init_orig, # Split initial train data (scaled and original)\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y_train_init\n",
    ")\n",
    "print(f\"Train/Validation split: Final Train ({X_train_final.shape[0]}), Validation ({X_val.shape[0]})\")\n",
    "print(\"Digits data prepared and split into Train/Validation/Test sets.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91292bfe",
   "metadata": {},
   "source": [
    "## SOM Implementation & Training\n",
    "\n",
    "Define SOM parameters and train two SOMs (4x4 and 20x20) on the final training data. Quantization Error on train and validation sets is calculated. Hyperparameters should be tuned based on validation performance (QE and classification accuracy from Task 2 validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f8f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOM Hyperparameters defined:\n",
      "  Small (4x4): Sigma=1.0, LR=0.5, Iter=10000, Init=PCA\n",
      "  Large (20x20): Sigma=3.0, LR=0.5, Iter=15000, Init=Random\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define SOM parameters\n",
    "som_grid_size_small = (4, 4)\n",
    "som_grid_size_large = (20, 20)\n",
    "n_features = X_train_final.shape[1] \n",
    "\n",
    "# Hyperparameters for Small SOM\n",
    "sigma_small = 1.0\n",
    "lr_small = 0.5              \n",
    "iterations_small = 10000\n",
    "init_method_small = \"PCA\"\n",
    "\n",
    "# Hyperparameters for Large SOM\n",
    "sigma_large = 3.0\n",
    "lr_large = 0.5             \n",
    "iterations_large = 15000\n",
    "init_method_large = \"Random\"\n",
    "\n",
    "print(\"SOM Hyperparameters defined:\")\n",
    "print(f\"  Small (4x4): Sigma={sigma_small}, LR={lr_small}, Iter={iterations_small}, Init={init_method_small}\")\n",
    "print(f\"  Large (20x20): Sigma={sigma_large}, LR={lr_large}, Iter={iterations_large}, Init={init_method_large}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbf31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
